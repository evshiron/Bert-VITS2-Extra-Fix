{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert-VITS2-Extra-Fix\n",
    "\n",
    "Note: `train_ms.py` doesn't work on macOS at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/evshiron/Bert-VITS2-Extra-Fix\n",
    "!cd Bert-VITS2-Extra-Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.0\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download required models\n",
    "\n",
    "# bert\n",
    "%pushd bert\n",
    "!curl -L 'https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin?download=true' > chinese-roberta-wwm-ext-large/pytorch_model.bin\n",
    "!curl -L 'https://huggingface.co/ku-nlp/deberta-v2-large-japanese-char-wwm/resolve/main/pytorch_model.bin?download=true' > deberta-v2-large-japanese-char-wwm/pytorch_model.bin\n",
    "!curl -L 'https://huggingface.co/microsoft/deberta-v3-large/resolve/main/pytorch_model.bin?download=true' > deberta-v3-large/pytorch_model.bin\n",
    "!curl -L 'https://huggingface.co/microsoft/deberta-v3-large/resolve/main/pytorch_model.generator.bin?download=true' > deberta-v3-large/pytorch_model.generator.bin\n",
    "!curl -L 'https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B/resolve/main/pytorch_model.bin?download=true' > Erlangshen-MegatronBert-1.3B-Chinese/pytorch_model.bin\n",
    "%popd\n",
    "\n",
    "# slm\n",
    "!curl -L 'https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin?download=true' > slm/wavlm-base-plus/pytorch_model.bin\n",
    "\n",
    "# g2pW\n",
    "!curl -L 'https://openi.pcl.ac.cn/Stardust_minus/Bert-VITS2/modelmanage/f4977cc4-3784-4a52-a605-21b5684f3d8f/downloadsingle?parentDir=&fileName=g2pW.onnx' > g2pW/g2pW.onnx\n",
    "\n",
    "# emotional\n",
    "!curl -L 'https://huggingface.co/laion/clap-htsat-fused/resolve/main/pytorch_model.bin?download=true' > emotional/clap-htsat-fused/pytorch_model.bin\n",
    "\n",
    "# pretrained models\n",
    "!mkdir pretrained_models\n",
    "%pushd pretrained_models\n",
    "!curl -L 'https://openi.pcl.ac.cn/Stardust_minus/Bert-VITS2/modelmanage/7ed55f37-467f-4212-9cde-ae312fbf0c1d/downloadsingle?parentDir=&fileName=G_0.pth' > G_0.pth\n",
    "!curl -L 'https://openi.pcl.ac.cn/Stardust_minus/Bert-VITS2/modelmanage/7ed55f37-467f-4212-9cde-ae312fbf0c1d/downloadsingle?parentDir=&fileName=D_0.pth' > D_0.pth\n",
    "!curl -L 'https://openi.pcl.ac.cn/Stardust_minus/Bert-VITS2/modelmanage/7ed55f37-467f-4212-9cde-ae312fbf0c1d/downloadsingle?parentDir=&fileName=WD_0.pth' > WD_0.pth\n",
    "!curl -L 'https://openi.pcl.ac.cn/Stardust_minus/Bert-VITS2/modelmanage/7ed55f37-467f-4212-9cde-ae312fbf0c1d/downloadsingle?parentDir=&fileName=DUR_0.pth' > DUR_0.pth\n",
    "%popd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: unpack zips into Data folder from Google Drive\n",
    "\n",
    "!mkdir Data\n",
    "%pushd Data\n",
    "!unzip /content/drive/MyDrive/Bert-VITS2-Extra-Fix/*.zip\n",
    "%popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='MODEL_NAME'\n",
    "\n",
    "device='cuda'\n",
    "# device='mps'\n",
    "# device='cpu'\n",
    "\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Datasets\n",
    "\n",
    "```\n",
    "├── Data\n",
    "│   ├── MODEL_NAME\n",
    "│   │   ├── esd.list\n",
    "│   │   ├── raw\n",
    "│   │   │   ├── ****.wav\n",
    "│   │   │   ├── ****.wav\n",
    "│   │   │   ├── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate configs\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "import utils\n",
    "\n",
    "def get_paths_for_model_name(model_name):\n",
    "    base_dir = os.path.join(\"./Data\", model_name)\n",
    "    label_path = os.path.join(base_dir, \"esd.list\")\n",
    "    train_path = os.path.join(base_dir, \"train.list\")\n",
    "    val_path = os.path.join(base_dir, \"val.list\")\n",
    "    config_path = os.path.join(base_dir, \"configs\", \"config.json\")\n",
    "    return base_dir, label_path, train_path, val_path, config_path\n",
    "\n",
    "\n",
    "base_dir, label_path, train_path, val_path, config_path = get_paths_for_model_name(model_name)\n",
    "\n",
    "# use existing or default config\n",
    "if os.path.isfile(config_path):\n",
    "    config = json.load(open(config_path, \"r\", encoding=\"utf-8\"))\n",
    "else:\n",
    "    config = json.load(open(\"configs/config.json\", \"r\", encoding=\"utf-8\"))\n",
    "config[\"data\"][\"training_files\"] = train_path\n",
    "config[\"data\"][\"validation_files\"] = val_path\n",
    "config[\"train\"][\"batch_size\"] = batch_size\n",
    "config_dir = os.path.join(base_dir, \"configs\")\n",
    "if not os.path.isdir(config_dir):\n",
    "    os.mkdir(config_dir)\n",
    "model_dir = os.path.join(base_dir, \"models\")\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"config.yml\"):\n",
    "    shutil.copy(src=\"default_config.yml\", dst=\"config.yml\")\n",
    "\n",
    "\n",
    "with open(\"default_config.yml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "data[\"dataset_path\"] = base_dir\n",
    "data[\"bert_gen\"][\"device\"] = device\n",
    "data[\"emo_gen\"][\"device\"] = device\n",
    "data[\"webui\"][\"device\"] = device\n",
    "with open(\"config.yml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump(data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess audios\n",
    "\n",
    "in_dir = os.path.join(base_dir, \"raw\")\n",
    "out_dir = os.path.join(base_dir, \"wavs\")\n",
    "\n",
    "!python resample_legacy.py --sr 44100 --in_dir {in_dir} --out_dir {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess labels\n",
    "\n",
    "lines = open(label_path, \"r\", encoding=\"utf-8\").readlines()\n",
    "with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in lines:\n",
    "        path, speaker, language, text = line.strip().split(\"|\")\n",
    "        path = os.path.join(base_dir, \"wavs\", os.path.basename(path)).replace(\n",
    "            \"\\\\\", \"/\"\n",
    "        )\n",
    "        f.writelines(f\"{path}|{speaker}|{language}|{text}\\n\")\n",
    "\n",
    "!python preprocess_text.py --transcription-path {label_path} --train-path {train_path} --val-path {val_path} --config-path {config_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bert checkpoints\n",
    "\n",
    "!python bert_gen.py --config {config_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate clap checkpoints\n",
    "\n",
    "!python clap_gen.py --config {config_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp pretrained_models/*.pth {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python train_ms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "data[\"webui\"][\"model\"] = os.path.relpath(utils.latest_checkpoint_path(model_dir, \"G_*.pth\"), base_dir)\n",
    "with open(\"config.yml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump(data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python webui.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
